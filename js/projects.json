[{
   "id": "customization",
   "title": "<strong>Direct Customization:</strong><br> Affordances and Preview for Personalization",
   "pictures": ["customization_0.png", "customization_1.png", "customization_2.png", "customization_3.png", "customization_4.png", "customization_5.png"],
   "icon": "customization-icon.png",
   "detailsVisible": false,
   "pictureVisible": false,
   "links": [{
      "text": "(work in progress)",
      "href": ""
   }],
   "description": "Customization panels are the most common customization mechanism in today's software. Often implemented as dialog boxes, they let users modify their software via a set of predefined customization options. However, these panels are how developers think about customization: changing the values of some obscure parameters in a config file. We propose to take the users' side on customization, by embedding it as much as possible in the interface of the app, which they are already familiar with. We are exploring how to add affordances, preview and undo of the customization options available, to create a more direct form of customization.",
   "process": "I started by surveying a large number of apps, both on the desktop and on smartphones, to see which customization mechanisms are offered to users today. I found that most apps implement a very similar settings panel, with a bunch of checkboxes and drop-downs. Unfortunately, these panels have serious usability shortcomings, as they don't provide affordances, preview nor undo. My idea is to remove these \"proxys\" to let users change directly the app interface. After surveying another set of apps to check that this approach was feasible, I designed a direct customization mechanism that maps settings to visual elements in the interface. I then built a web prototype with several variants, testing and refining them regularly with potential users. I managed to hook this prototype into Wunderlist (a popular todolist app), so that my software replaces their settings panel. I am now planning an experiment on Mechanical Turk to evaluate this system",
   "tools": "jQuery, Angular.js",
   "tags": ["Interaction Design", "Visual Design", "Web", "User Research"]
}, {
   "id": "paperquest",
   "title": "<strong>PaperQuest:</strong><br> A Visualization Tool to Support Literature Review",
   "pictures": ["paperquest_0.png", "paperquest_1.png", "paperquest_2.png"],
   "icon": "paperquest-icon.png",
   "detailsVisible": false,
   "pictureVisible": false,
   "links": [{
      "text": "demo",
      "href": "//www.cs.ubc.ca/~aponsard/paperquest"
   }, {
      "text": "paper",
      "href": "res/PaperQuest.pdf"
   }],
   "description": "The literature review is a key component of academic research, that allows researchers to build upon each other’s work. Modern search engines enable fast access to publications, but there is a lack of support for filtering out the vast majority of papers that are irrelevant to the current research focus. We present PaperQuest, a visualization tool that supports efficient decision making, by only displaying the information useful at a given step of the exploration process. We propose a relevance algorithm to find and sort papers that are likely to be relevant to users, based on the papers they have expressed interest in before and the number of citations. The current implementation uses papers from the CHI and UIST conferences, and citation counts from Google Scholar, but is easily extensible to other domains of the literature.",
   "team": "Francisco Escalona (\"Pax\")",
   "process": "We began by asking researchers how they do literature reviews, and we found that most were following a very similar process: searching with keywords on Google Scholar, opening papers links in a new tab, reading the abstract and, if the paper seemed interesting, downloading the pdf for reading it later. Our goal was to support this lightweight decision process, but make it more powerful by leveraging previous searches and selected papers. Our most important decision was to represent the papers network as a zoomable and ordered list, instead the traditional node-link diagram. We did a lot of sketches to find: the overall layout of the visualization; the visual encoding of the paper metrics; and the browsing interactions. Pax worked on retrieving the data, processing it and serving it in an Object-Oriented way, while I focused on the visuals and the interactions.",
   "tools": "D3.js",
   "tags": ["Interaction Design", "Visual Design", "Web", "User Research"]
}, {
   "id": "twistAndPulse",
   "title": "<strong>Twist and Pulse:</strong> Ephemeral Adaptation to improve Icon Selection on Smartphones <em> (Graphics Interface 2015) </em>",
   "pictures": ["twistAndPulse_0.png", "twistAndPulse_1.png", "twistAndPulse_2.png"],
   "icon": "twistAndPulse-icon.png",
   "detailsVisible": false,
   "pictureVisible": false,
   "links": [{
      "text": "video",
      "href": "//youtu.be/EhsgFFhHUuA"
   }, {
      "text": "paper",
      "href": "res/TwistAndPulse-GI2015.pdf"
   }, {
      "text": "slides.pdf",
      "href": "res/TwistAndPulse-GI2015-slides.pdf"
   }, {
      "text": "slides.pptx",
      "href": "res/TwistAndPulse-GI2015.pptx"
   }],
   "description": "The concept of ephemeral adaptation was introduced to reduce visual search time in GUI menus, while preserving spatial consistency and minimizing distraction. We extend this concept to the visual search of app icons on smartphones in order to speed up launching apps from a homescreen. We created ephemeral highlighting effects based on preattentive visual properties including size, orientation, color, opacity and blur. A controlled experiment showed that Twist (icon rotates back and forth) and Pulse (icon grows and shrinks) improve search time performance by 8-10% over a control condition with no highlighting.",
   "team": "Kamyar Ardekani, Kailun Zhang",
   "process": "To find inspiration on new ways to launch apps on smartphones, we surveyed many custom Android homescreens and themes, looking at the type of icons, widgets and animations they were using. Given the growing number of apps that people install on their phone, we decided to focus on helping users find the app they're looking for faster. We prototyped some visual effects with PowerPoint, but quickly realized that we needed more power and control on the animations. We then built an Android app mimicking a traditional homescreen, with a variety of highlighting effects that we tested on potential users. Finally we designed and ran a very precise experiment on the two most promising effects.",
   "tools": "Android",
   "tags": ["Interaction Design", "Visual Design", "Mobile", "User Research"]
}, {
   "id": "calendarTodolists",
   "title": "Integrating calendar and to-do lists",
   "pictures": ["calendarTodolists_0.png", "calendarTodolists_1.png", "calendarTodolists_2.png", "calendarTodolists_3.png", "calendarTodolists_4.png", "calendarTodolists_5.png"],
   "icon": "calendarTodolists-icon.png",
   "detailsVisible": false,
   "pictureVisible": false,
   "links": [{
      "text": "demo",
      "href": "//www.cs.ubc.ca/~aponsard/hci-med-fi-prototype"
   }, {
      "text": "paper",
      "href": "res/NurseryWeb-stage4.pdf"

   }],
   "description": "We address a major issue in task management: the lack of support for time-sensitive deadlines. On the one hand, calendars are time-centric tools, appropriate for keeping track of events, but they are not great for planning for deadlines. On the other hand, todo lists are task-centric tools, excellent for keeping track of tasks and subtasks; but it is hard to visualize time from a text-only format. Our proposed solution is to combine the strength of both types of tools by tightly coupling them.",
   "team": "Francisco Escalona, Kamyar Ardekani",
   "process": "We began by asking our target population (post-secondary students) how they manage their academic workload, including short-term assignments, long-term projects and studying for exams. Most were using a generic calendar tool, and many were using a todo list app. We identified several problems: entering new tasks, estimating business level and planning work. We focused on the last two, because we believe solutions already exist for the first one (e.g. crowdsourcing tasks input). After several brainstormings, we designed an interface that integrates calendar and todolists. We sketched a low-fi mockup to test our design with potential users, before implementing a high-fidelity prototype and testing it with another set of users.",
   "tools": "Balsamiq, jQuery, Ember.js",
   "tags": ["Interaction Design", "Visual Design", "Web", "User Research"]
}, {
   "id": "portfolio",
   "title": "Online portfolio",
   "pictures": ["portfolio_0.png", "portfolio_1.png"],
   "icon": "portfolio-icon.png",
   "detailsVisible": false,
   "pictureVisible": false,
   "links": [{
      "text": "home",
      "href": "#!/"
   }],
   "description": "Since I was completely free for this project, I wanted to try to design something very minimalistic. Both the visual style and the information architecture are simple: one page about me, one page for my projects. My paraph on the landing screen is the key to the entire website: it is a distinctive personal element; it provides navigation to the different pages; and its circular shape is used consistently troughout the website. The vertical ligne shared by the A and the P can be found in each picture, to reinforce the visual structure. Using the circle shape consistently creates a lot of visual constraints across the website, which makes each page rather tricky to design—especially since the visual constraints must be satisfied for each screen size. While designing the unfolding animation for the logo, I also realized that creating smooth, pleasant motions is not enough: the intermediate states of the logo must also look good, each one on their own.",
   "tools": "Angular.js, D3.js, Bootstrap, ffmpeg",
   "tags": ["Interaction Design", "Visual Design", "Web", "Mobile"]
}, {
   "id": "boa",
   "title": "Multi-scale video exploration techniques",
   "pictures": ["boa_0.png"],
   "icon": "boa-icon.png",
   "detailsVisible": false,
   "pictureVisible": false,
   "links": [{
      "text": "(demo coming soon)",
      "href": ""
   }],
   "description": "I've always been intrigued by that simple question: 'Why is it still so cumbersome to browse and edit videos compared to text files?'. For instance, finding a particular scene in a movie is much more difficult than finding a sentence in a text. During an internship at INRIA, I had access to a wall-sized display made of 32 high resolution monitors. It allowed me to 'lay out time in space', i.e. to project the temporal dimension of the video on the two spatial dimensions of this giant screen. I built three prototypes to try out different interaction techniques, such as temporal zoom based on the distance to the screen. One of my design goals was to preserve as much as possible the continuity of the video while projecting it, which led to the use of a 'snake' projection.",
   "tools": "Node.js, jQuery, ffmpeg, HTML5 video player",
   "tags": ["Interaction Design", "Web"]
}, {
   "id": "geppm",
   "title": "Event scheduling website for an equal opportunity program",
   "pictures": ["geppm_0.png"],
   "icon": "geppm-icon.png",
   "detailsVisible": false,
   "pictureVisible": false,
   "links": [{
      "text": "demo",
      "href": "//www.cs.ubc.ca/~aponsard/geppm"
   }],
   "description": "A friend and I built this website for GEPPM, an equal opportunity program I was participating in at Ecole polytechnique. We had two types of users: regular tutors who needed to know where and when to meet their tutees, depending on the group and grade; and admins who assign tutors to groups and schedule events for all the groups. My friend set up the database and the events management on the back end, while I built the front end in AJAX, designed the appearance of the website and handled the account management features. You can try the website with the login a@a.com and the password 'a'.",
   "tools": "PHP, MySQL, AJAX",
   "tags": ["Interaction Design", "Visual Design", "Web"]
}, {
   "id": "drone",
   "title": "Image processing for drone stabilization",
   "pictures": ["drone_0.png"],
   "icon": "drone-icon.png",
   "detailsVisible": false,
   "pictureVisible": false,
   "links": [{
      "text": "video_flight",
      "href": "//youtu.be/onzO0s7Fn6c"
   }, {
      "text": "video_algorithm",
      "href": "//youtu.be/WZTOihh9bhI"
   }],
   "description": "In this team project, we worked on a small quadcopter drone, built the year before by another team. It could fly on its own, automatically controlled by an Inertial Measurement Unit; but an IMU is not accurate enough to prevent drifting. To measure the drone's horizontal speed accurately and frequently, our approach was to put a camera under the drone, facing the ground, and use image processing algorithms to estimate the motion relative to the ground. I was in charge of developing the image processing part. With the help of a computer vision expert, I selected the FAST algorithm to detect salient features in each frame of the video stream, then match these features across frames based on a similarity metric. The homographic matrix between two consecutive frames is then computed from these individual motion vectors via a RANSAC voting scheme. Two components of this matrix are the horizontal translation of the camera between two frames.",
   "tools": "C++, OpenCV",
   "tags": ["Other"]
}, {
   "id": "sasuke",
   "title": "Platform game: Path of a Ninja",
   "pictures": ["sasuke_0.png"],
   "icon": "sasuke-icon.png",
   "detailsVisible": false,
   "pictureVisible": false,
   "links": [{
      "text": ".exe",
      "href": "res/sasuke.exe"
   }],
   "description": "A platform game I developed a long time ago, in which you control a ninja who jumps from building to building and throws shurikens. It was my first encounter with concepts like Object-Oriented Programming and the event loop. But the most difficult part was to handle gravity and collisions, and change the sprites appropriately—especially since the images I was using had a little bit of depth (2.5D).",
   "tools": "Game Maker Studio",
   "tags": ["Other"]
}, {
   "id": "avion",
   "title": "Converting my RC car into an RC plane",
   "pictures": ["avion_0.png"],
   "icon": "avion-icon.png",
   "detailsVisible": false,
   "pictureVisible": false,
   "links": [{
      "text": "video",
      "href": "//youtu.be/-y7MyrMMm-k"
   }],
   "description": "I had a neat RC car as a teenager, but I grew tired of it. So I decided to turn it into a plane. I adapted some plans from an RC magazine to accommodate the size of the car's engine and the weight of the battery pack, and built the structure of the plane in balsa and a special type of polystyrene. The tricky thing was that a plane has at least three degrees of freedom, but my RC controller had only two channels, so I had to use the engine for both speed and altitude. It did fly (multiple times!), but I quickly realized that flying a plane is much, much harder than driving a car!",
   "tools": "saw, glue, scalpel, soldering iron",
   "tags": ["Other"]
}]
